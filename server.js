const express = require('express');
const cors = require('cors');
const multer = require('multer');
const bodyParser = require('body-parser');
const fs = require('fs-extra');
const path = require('path');
require('dotenv').config();

// OpenAI API
const OpenAI = require('openai');

// Initialize OpenAI
let openaiClient;
try {
    if (process.env.OPENAI_API_KEY) {
        openaiClient = new OpenAI({
            apiKey: process.env.OPENAI_API_KEY
        });
        console.log('✅ OpenAI initialized successfully');
    } else {
        console.log('⚠️  OPENAI_API_KEY not found, using fallback responses');
    }
} catch (error) {
    console.log('⚠️  Failed to initialize OpenAI, using fallback responses:', error.message);
}

const app = express();
const PORT = process.env.PORT || 3000;

// Middleware
app.use(cors());
app.use(bodyParser.json({ limit: '50mb' }));
app.use(bodyParser.urlencoded({ extended: true, limit: '50mb' }));
app.use(express.static('frontend'));

// Configure multer for file uploads
const upload = multer({ 
    dest: 'uploads/',
    limits: { fileSize: 10 * 1024 * 1024 } // 10MB limit
});

// Global state (in production, use a proper database)
let conversationHistory = [];
let currentMode = 'chat';
let uploadedQuestions = [];
let uploadedReturnLog = [];
let activeChatSession = null; // Store the active chat session for context

// Predefined questions stored on server
const predefinedQuestions = {
    naive: [
        "How did you first come across the idea of using GenAI (e.g., ChatGPT, Gemini) to help with job interviews?",
        "Can you walk us through a time when you used GenAI as part of your job interview preparation process?",
        "Has AI ever played a major role in your interview preparation? Tell us about that experience.",
        "What kinds of tasks did you rely on GenAI for most heavily when preparing for interviews — writing, brainstorming, practice Q&A, etc.?",
        "Have you ever reused or saved AI-generated answers, phrases, or stories across multiple interviews? What was that like?",
        "Can you share an example of a GenAI-generated response you felt especially proud of using in an interview setting?",
        "Have you ever gone into an interview feeling like you were \"backed up\" by AI? What did that feel like?",
        "Have you ever thought about or actually used GenAI during a live or remote job interview? What happened?",
        "If you've ever used notes or prompts generated by GenAI during an interview, how did you prepare and manage that?",
        "Have you ever run AI in the background during a coding or case challenge? What led you to that choice?",
        "Tell us about a time when you felt like AI gave you a competitive edge during an interview process.",
        "Can you recall a time when you pretended that an AI-generated idea or story was your own in an interview? What made you do that?",
        "Did you ever experience a close call where your use of GenAI almost got you in trouble or exposed? What was that like?",
        "Looking back, was there ever a moment when you thought \"maybe I crossed a line\" using GenAI for a job application?",
        "Can you share a story about a time when AI actually hurt your performance in a job interview or made things worse?",
        "Where do you personally draw the line between getting help and cheating when using AI for interviews?",
        "Have you had conversations with peers about \"how far is too far\" when using GenAI? What do people say?",
        "If you had a chance to do it all over again, would you use AI the same way? Why or why not?",
        "Are there any stories you'd like to share — surprising, funny, embarrassing, or impressive — about your journey using AI in job interviews?"
    ],
    neutral: [
        "How did you first come across the idea of using GenAI (e.g., ChatGPT, Gemini) to help with job interviews?",
        "Can you walk us through a time when you used GenAI as part of your job interview preparation process?",
        "Has AI ever played a major role in your interview preparation? Tell us about that experience.",
        "What kinds of tasks did you rely on GenAI for most heavily when preparing for interviews — writing, brainstorming, practice Q&A, etc.?",
        "Have you ever reused or saved AI-generated answers, phrases, or stories across multiple interviews? What was that like?",
        "Can you share an example of a GenAI-generated response you felt especially proud of using in an interview setting?",
        "Have you ever gone into an interview feeling like you were \"backed up\" by AI? What did that feel like?",
        "Have you ever thought about or actually used GenAI during a live or remote job interview? What happened?",
        "If you've ever used notes or prompts generated by GenAI during an interview, how did you prepare and manage that?",
        "Have you ever run AI in the background during a coding or case challenge? What led you to that choice?",
        "Tell us about a time when you felt like AI gave you a competitive edge during an interview process.",
        "Can you recall a time when you pretended that an AI-generated idea or story was your own in an interview? What made you do that?",
        "Did you ever experience a close call where your use of GenAI almost got you in trouble or exposed? What was that like?",
        "Looking back, was there ever a moment when you thought \"maybe I crossed a line\" using GenAI for a job application?",
        "Can you share a story about a time when AI actually hurt your performance in a job interview or made things worse?",
        "Where do you personally draw the line between getting help and cheating when using AI for interviews?",
        "Have you had conversations with peers about \"how far is too far\" when using GenAI? What do people say?",
        "If you had a chance to do it all over again, would you use AI the same way? Why or why not?",
        "Are there any stories you'd like to share — surprising, funny, embarrassing, or impressive — about your journey using AI in job interviews?"
    ],
    featured: [
        "How did you first come across the idea of using GenAI (e.g., ChatGPT, Gemini) to help with job interviews?",
        "Can you walk us through a time when you used GenAI as part of your job interview preparation process?",
        "Has AI ever played a major role in your interview preparation? Tell us about that experience.",
        "What kinds of tasks did you rely on GenAI for most heavily when preparing for interviews — writing, brainstorming, practice Q&A, etc.?",
        "Have you ever reused or saved AI-generated answers, phrases, or stories across multiple interviews? What was that like?",
        "Can you share an example of a GenAI-generated response you felt especially proud of using in an interview setting?",
        "Have you ever gone into an interview feeling like you were \"backed up\" by AI? What did that feel like?",
        "Have you ever thought about or actually used GenAI during a live or remote job interview? What happened?",
        "If you've ever used notes or prompts generated by GenAI during an interview, how did you prepare and manage that?",
        "Have you ever run AI in the background during a coding or case challenge? What led you to that choice?",
        "Tell us about a time when you felt like AI gave you a competitive edge during an interview process.",
        "Can you recall a time when you pretended that an AI-generated idea or story was your own in an interview? What made you do that?",
        "Did you ever experience a close call where your use of GenAI almost got you in trouble or exposed? What was that like?",
        "Looking back, was there ever a moment when you thought \"maybe I crossed a line\" using GenAI for a job application?",
        "Can you share a story about a time when AI actually hurt your performance in a job interview or made things worse?",
        "Where do you personally draw the line between getting help and cheating when using AI for interviews?",
        "Have you had conversations with peers about \"how far is too far\" when using GenAI? What do people say?",
        "If you had a chance to do it all over again, would you use AI the same way? Why or why not?",
        "Are there any stories you'd like to share — surprising, funny, embarrassing, or impressive — about your journey using AI in job interviews?"
    ]
};

// Helper function to manage conversation context
function manageConversationContext() {
    // Keep track of conversation context without resetting
    // This allows for continuous conversation tracking
    const maxMessages = 1000; // Increased limit to allow longer conversations
    
    if (conversationHistory.length > maxMessages) {
        console.log('Conversation getting very long, keeping context but trimming history for performance');
        
        // Keep only recent messages in history for reference but maintain chat session
        conversationHistory = conversationHistory.slice(-100);
    }
}

// API Routes

// Test API Connection
app.get('/api/test_connection', (req, res) => {
    res.json({ 
        status: 'success', 
        message: 'Backend server is running',
        timestamp: new Date().toISOString(),
        conversation_context: {
            has_active_session: activeChatSession !== null,
            message_count: conversationHistory.length,
            current_mode: currentMode
        }
    });
});

// Get predefined questions API
app.get('/api/predefined_questions/:mode', (req, res) => {
    try {
        const { mode } = req.params;
        
        if (!predefinedQuestions[mode]) {
            return res.status(400).json({ error: 'Invalid mode' });
        }
        
        res.json({
            success: true,
            questions: predefinedQuestions[mode],
            mode: mode
        });
    } catch (error) {
        console.error('Get predefined questions error:', error);
        res.status(500).json({ error: 'Internal server error' });
    }
});

// Debug API to show conversation context
app.get('/api/debug_context', (req, res) => {
    res.json({
        conversation_history: conversationHistory,
        active_chat_session: activeChatSession !== null,
        current_mode: currentMode,
        uploaded_questions: uploadedQuestions,
        uploaded_return_log: uploadedReturnLog
    });
});

// Chat API
app.post('/api/chat', async (req, res) => {
    try {
        const { message, step = 0, questionMode = false, currentQuestion = null, predefinedQuestions = [], isFinalQuestion = false } = req.body;
        
        if (!message || message.trim() === '') {
            return res.status(400).json({ error: 'Message is required and cannot be empty' });
        }

        // Add user message to history
        conversationHistory.push({
            role: 'user',
            content: message,
            timestamp: new Date().toISOString(),
            step: step
        });
        
        console.log(`Chat API: Received message="${message}", questionMode=${questionMode}, currentQuestion="${currentQuestion}"`);

        // Manage conversation context (reset if too long)
        manageConversationContext();

        // Generate AI response using OpenAI or fallback
        let aiResponse;
        let questionCompleted = false;
        
        if (openaiClient) {
            try {
                // Enhanced system prompt for the chatbot with question guidance
                let systemPrompt = `You are a helpful, friendly, and knowledgeable AI assistant. Keep your responses short and concise.`;
                
                // If in question mode, enhance the system prompt with predefined questions
                if (questionMode && predefinedQuestions && predefinedQuestions.length > 0) {
                    const finalQuestionNote = isFinalQuestion ? 
                        "\n\nFINAL QUESTION INSTRUCTIONS: This is the LAST question in the conversation. You should engage in natural follow-up conversation about this topic, asking 3-4 follow-up questions to gather detailed information before ending. Do NOT use 'NEXT_QUESTION:' for the final question. After sufficient discussion (3-4 exchanges), provide a natural conclusion that:\n1. Thanks the user for their participation\n2. Briefly summarizes what you've learned about them\n3. Clearly indicates the conversation is complete\n\nCRITICAL: Only end the conversation after you've had a meaningful discussion with 3-4 follow-up questions. Do not rush to end the conversation.\n\nExample ending: 'Thank you so much for sharing all of this with me! I've really enjoyed learning about your background, your work at MIT, and your love for hiking. You seem like a fascinating person. This concludes our conversation - thank you for your time!'" : 
                        "";
                    
                    systemPrompt = `You are a helpful, friendly, and knowledgeable AI assistant conducting a conversation based on predefined questions. 

Your role is to ask the predefined questions naturally and engage in follow-up conversation based on the user's responses. You should:

1. Start with the general topic from the predefined question
2. Gradually ask more specific and personal follow-up questions to gather concrete, real stories
3. Show genuine interest in their answers
4. Keep responses concise but engaging
5. Move to the next predefined question when you feel the current topic has been sufficiently explored

Current question context: ${currentQuestion || 'Starting conversation'}

Predefined questions to cover: ${predefinedQuestions.join(', ')}

CONVERSATION FLOW INSTRUCTIONS:
- Always start with the general topic from the predefined question
- Gradually ask more specific and personal follow-up questions to gather concrete, real stories
- The follow-up questions should be more generic and focused on concrete, real experiences
- Example flow: General topic → Specific experience → Personal story → Real example
- Generate your own follow-up questions based on the user's responses to gather more specific and personal information

CRITICAL INSTRUCTION: You should naturally engage in conversation about the current question and ask relevant follow-up questions based on the user's responses. 

When you feel you have gathered sufficient information about the current question and the conversation about this topic feels complete, you MUST indicate that you're moving to the next question by starting your response with "NEXT_QUESTION:" followed by your response.

IMPORTANT: When using "NEXT_QUESTION:", your response should ONLY contain:
- A brief acknowledgment of what the user shared
- A smooth transition to the next question
- The actual next question

DO NOT include any additional follow-up questions or commentary after asking the next question. The "NEXT_QUESTION:" response should be a clean transition to the new topic.

CRITICAL: Your "NEXT_QUESTION:" response must end with the main question. Do not add any additional questions, clarifications, or follow-ups after the main question.

Guidelines for when to move to the next question:
- When the user has provided substantial information about the current question
- When the conversation about the current question feels complete and natural
- When you have a good understanding of the user's response to the current question
- When you've had enough meaningful discussion about the current topic
- Trust your judgment - you can move on after just one exchange if the user has given a comprehensive answer, or continue longer if they seem to want to elaborate

Example of a proper "NEXT_QUESTION:" response:
"Thanks for sharing that! Now, let me ask you, what is your occupation?"

NOT like this (which would cause double questions):
"Thanks for sharing that! Now, let me ask you, what is your occupation? Do you enjoy your work?"

CONVERSATION FLOW EXAMPLES:
- Start: "How to use GenAI to prepare for a job interview" (general topic)
- Follow-up: Ask about their specific experiences, such as "What was the first time that you used AI to prepare for a job interview?" or "Can you tell me about a specific tool you've used for interview preparation?"
- Continue with more specific questions about their experience, tools used, outcomes, etc.
- Generate follow-up questions that ask for concrete, personal stories and real examples

The response should be exactly ONE transition sentence followed by ONE main question, nothing more.

Remember to be conversational and ask follow-up questions based on what the user shares. Don't rush through questions, but also don't artificially extend conversations that feel complete.${finalQuestionNote}`;
                }

                // Build messages array for OpenAI
                const messages = [
                    { role: 'system', content: systemPrompt }
                ];

                // Add conversation history
                conversationHistory.forEach(msg => {
                    messages.push({
                        role: msg.role,
                        content: msg.content
                    });
                });

                // If in question mode, add context to help the AI understand the current state
                let userMessage = message;
                if (questionMode && currentQuestion) {
                    const finalQuestionContext = isFinalQuestion ? 
                        " This is the FINAL question - engage in natural follow-up conversation with 3-4 questions before ending with a thank you and summary." : 
                        "";
                    
                    userMessage = `[CONTEXT: Current question is "${currentQuestion}". You are in a conversation flow with predefined questions. Trust your judgment on when to move to the next question based on the natural flow of conversation.${finalQuestionContext}]\n\nUser: ${message}`;
                    console.log(`Question Mode Context: Current question="${currentQuestion}", Message="${userMessage}"`);
                }

                // Add the current user message
                messages.push({ role: 'user', content: userMessage });

                const completion = await openaiClient.chat.completions.create({
                    model: "gpt-4o",
                    messages: messages,
                    max_tokens: 1000,
                    temperature: 0.7
                });

                aiResponse = completion.choices[0].message.content;
                
                // Check if LLM signaled question completion or conversation ending
                if (questionMode && aiResponse.startsWith('NEXT_QUESTION:')) {
                    questionCompleted = true;
                    aiResponse = aiResponse.replace('NEXT_QUESTION:', '').trim();
                    console.log('Question completed via NEXT_QUESTION signal');
                } else if (questionMode && isFinalQuestion) {
                    // Check if the final question response indicates conversation completion
                    const endingPatterns = [
                        /thank you.*sharing.*with me/i,
                        /thank you.*participation/i,
                        /concludes our conversation/i,
                        /conversation.*complete/i,
                        /enjoyed learning about you/i,
                        /thank you.*time/i
                    ];
                    
                    const hasEndingPattern = endingPatterns.some(pattern => pattern.test(aiResponse));
                    if (hasEndingPattern) {
                        questionCompleted = true;
                        console.log('Final question completed via conversation ending signal');
                    }
                }
                
            } catch (aiError) {
                console.error('AI API error:', aiError);
                aiResponse = `I apologize, but I'm having trouble processing your request right now. Please try again later. (Error: ${aiError.message})`;
            }
        } else {
            // Fallback response when AI is not available
            if (questionMode && currentQuestion) {
                aiResponse = `Thank you for sharing that information about "${message}". Let me ask you the next question: ${currentQuestion}`;
                questionCompleted = true; // Force completion in fallback mode
            } else {
                aiResponse = `This is a simulated response to: "${message}". In a real implementation, this would be processed by an AI model. To enable real AI responses, please configure a valid OPENAI_API_KEY environment variable.`;
            }
        }
        
        conversationHistory.push({
            role: 'assistant',
            content: aiResponse,
            timestamp: new Date().toISOString(),
            step: step
        });

        // Check if privacy detection is needed (featured mode)
        let privacyDetection = null;
        if (currentMode === 'featured') {
            try {
                // Use conversation context for enhanced privacy detection
                privacyDetection = await detectPrivacyWithAI(message, conversationHistory);
                if (!privacyDetection || privacyDetection.error) {
                    privacyDetection = detectPrivacyWithPatterns(message, conversationHistory);
                }
            } catch (error) {
                console.error('Privacy detection error in chat:', error);
                privacyDetection = detectPrivacyWithPatterns(message, conversationHistory);
            }
        }

        // Log question completion status for debugging
        if (questionMode) {
            console.log(`Question completion status: ${questionCompleted}`);
            console.log(`Final AI response being sent: "${aiResponse}"`);
        }
        
        res.json({
            success: true,
            bot_response: aiResponse,
            conversation_history: conversationHistory,
            step: step,
            privacy_detection: privacyDetection,
            question_completed: questionCompleted
        });
    } catch (error) {
        console.error('Chat API error:', error);
        res.status(500).json({ error: 'Internal server error' });
    }
});

// Privacy Detection API
app.post('/api/privacy_detection', async (req, res) => {
    try {
        const { user_message } = req.body;
        
        if (!user_message) {
            return res.status(400).json({ error: 'User message is required' });
        }

        // Enhanced AI-based privacy detection with conversation context and fallback to pattern matching
        let privacyResult = await detectPrivacyWithAI(user_message, conversationHistory);
        
        // If AI detection fails, fall back to pattern matching
        if (!privacyResult || privacyResult.error) {
            console.log('AI privacy detection failed, using pattern matching fallback');
            privacyResult = detectPrivacyWithPatterns(user_message, conversationHistory);
        }

        res.json(privacyResult);
    } catch (error) {
        console.error('Privacy detection error:', error);
        // Final fallback to pattern matching
        const fallbackResult = detectPrivacyWithPatterns(req.body.user_message, conversationHistory);
        res.json(fallbackResult);
    }
});

// AI-based privacy detection function with conversation context
async function detectPrivacyWithAI(userMessage, conversationContext = null) {
    if (!openaiClient) {
        return { error: 'AI model not available' };
    }

    try {
        // Build context-aware prompt - only consider conversation before and after current message
        let contextInfo = '';
        
        if (conversationContext && conversationContext.length > 0) {
            // Find the current message index in the conversation
            const currentMessageIndex = conversationContext.findIndex(msg => msg.content === userMessage);
            
            if (currentMessageIndex !== -1) {
                // Get messages before and after the current message
                const beforeMessages = conversationContext.slice(0, currentMessageIndex);
                const afterMessages = conversationContext.slice(currentMessageIndex + 1);
                
                // Extract user messages from before and after
                const beforeUserMessages = beforeMessages
                    .filter(msg => msg.role === 'user')
                    .map(msg => msg.content)
                    .slice(-3); // Last 3 messages before
                
                const afterUserMessages = afterMessages
                    .filter(msg => msg.role === 'user')
                    .map(msg => msg.content)
                    .slice(0, 3); // First 3 messages after
                
                if (beforeUserMessages.length > 0 || afterUserMessages.length > 0) {
                    contextInfo = `\n\nCONVERSATION CONTEXT:\n`;
                    if (beforeUserMessages.length > 0) {
                        contextInfo += `Messages before: ${beforeUserMessages.join(' | ')}\n`;
                    }
                    if (afterUserMessages.length > 0) {
                        contextInfo += `Messages after: ${afterUserMessages.join(' | ')}`;
                    }
                }
            }
        }

        const privacyPrompt = `You are an expert in cybersecurity and data privacy. You are now
tasked to detect PII from the given text, using the following taxonomy only:

ADDRESS
IP_ADDRESS
URL
SSN
PHONE_NUMBER
EMAIL
DRIVERS_LICENSE
PASSPORT_NUMBER
TAXPAYER_IDENTIFICATION_NUMBER
ID_NUMBER
NAME
USERNAME
KEYS: Passwords, passkeys, API keys, encryption keys, and any
other form of security keys.GEOLOCATION: Places and locations, such as cities, provinces,
countries, international regions, or named infrastructures
(e.g., bus stops, bridges, etc.).

AFFILIATION: Names of organizations, such as public and private companies, schools, universities, public institutions,
prisons, healthcare institutions, non-governmental organizations, churches, etc.DEMOGRAPHIC_ATTRIBUTE: Demographic attributes of a
person, such as native language, descent, heritage, ethnicity,
nationality, religious or political group, birthmarks, ages,
sexual orientation, gender, and sex.TIME: Description of a specific date, time, or duration.HEALTH_INFORMATION: Details concerning an individual's
health status, medical conditions, treatment records, and
health insurance information.FINANCIAL_INFORMATION: Financial details such as bank account numbers, credit card numbers, investment records,
salary information, and other financial statuses or activities.EDUCATIONAL_RECORD: Educational background details, including academic records, transcripts, degrees, and certifications.

For the given message that a user sends to a chatbot, identify all the personally identifiable information using the above taxonomy only, and the entity_type should be selected from the all-caps categories.
Note that the information should be related to a real person not in a public context, but okay if not uniquely identifiable.
Result should be in its minimum possible unit.
Rewrite the text to abstract the protected information, without changing other parts.

Use this exact format:
{"privacy_issue": true/false, "type": "issue_category", "suggestion": "Before: \"<original>\"\nAfter: \"<safer>\"", "explanation": "brief_reason", "affected_text": "specific_text_that_poses_risk", "sensitive_text": "specific_text_that_poses_risk"}
If no privacy issues found, respond with: {"privacy_issue": false, "type": null, "suggestion": null, "explanation": null, "affected_text": null, "sensitive_text": null}

For example:
Input: <Text>I graduated from CMU, and I earn a six-figure
salary. Today in the office...</Text><ProtectedInformation>CMU,Today</ProtectedInformation>
Output JSON: {"privacy_issue": true, "type": "EDUCATIONAL_RECORD", "suggestion": "Before: \"I graduated from CMU, and I earn a six-figure salary. Today in the office...\"\nAfter: \"I graduated from [University], and I earn a six-figure salary. Today in the office...\"", "explanation": "The user's educational background and salary information are protected.", "affected_text": "CMU,Today", "sensitive_text": "CMU,Today"}

Current user message: "${userMessage}"${contextInfo}`;

        const completion = await openaiClient.chat.completions.create({
            model: "gpt-4o",
            messages: [
                { role: "system", content: "You are a privacy detection expert. Analyze messages for privacy and security issues considering conversation context and respond with ONLY valid JSON." },
                { role: "user", content: privacyPrompt }
            ],
            max_tokens: 800,
            temperature: 0.1
        });
        const responseText = completion.choices[0].message.content;
        
        // Clean the response text to extract JSON (remove markdown formatting)
        let cleanedResponse = responseText.trim();
        
        // Remove markdown code blocks if present
        if (cleanedResponse.startsWith('```json')) {
            cleanedResponse = cleanedResponse.replace(/^```json\s*/, '').replace(/\s*```$/, '');
        } else if (cleanedResponse.startsWith('```')) {
            cleanedResponse = cleanedResponse.replace(/^```\s*/, '').replace(/\s*```$/, '');
        }
        
        // Try to parse JSON response
        try {
            const privacyData = JSON.parse(cleanedResponse);
            
            // Handle both single object and array responses
            let processedData;
            
            if (Array.isArray(privacyData)) {
                console.log(`AI returned array with ${privacyData.length} privacy issues, using the first one`);
                // If AI returns an array of privacy issues, take the first one
                if (privacyData.length > 0) {
                    processedData = privacyData[0];
                } else {
                    // Empty array means no privacy issues
                    processedData = {
                        privacy_issue: false,
                        type: null,
                        suggestion: null,
                        explanation: null,
                        affected_text: null,
                        contextual_risk: null
                    };
                }
            } else {
                // Single object response
                processedData = privacyData;
            }
            
            // Validate the response format
            if (typeof processedData.privacy_issue === 'boolean') {
                return {
                    privacy_issue: processedData.privacy_issue,
                    type: processedData.type || null,
                    suggestion: processedData.suggestion || null,
                    explanation: processedData.explanation || null,
                    affected_text: processedData.affected_text || userMessage,
                    sensitive_text: processedData.sensitive_text || null
                };
            } else {
                throw new Error('Invalid privacy_issue field');
            }
        } catch (parseError) {
            console.error('Failed to parse AI privacy response:', parseError);
            console.error('Original response:', responseText);
            console.error('Cleaned response:', cleanedResponse);
            throw new Error('Invalid JSON response from AI');
        }
    } catch (error) {
        console.error('AI privacy detection error:', error);
        return { error: error.message };
    }
}

// Enhanced pattern-based privacy detection with conversation context
function detectPrivacyWithPatterns(userMessage, conversationContext = null) {
    const privacyIssues = [];
    const sensitivePatterns = [
        { 
            pattern: /\b\d{3}-\d{2}-\d{4}\b/, 
            type: 'Social Security Number',
            replacement: 'XXX-XX-XXXX',
            explanation: 'SSN detected'
        },
        { 
            pattern: /\b\d{4}[\s-]?\d{4}[\s-]?\d{4}[\s-]?\d{4}\b/, 
            type: 'Credit Card Number',
            replacement: '****-****-****-****',
            explanation: 'Credit card number detected'
        },
        { 
            pattern: /\b\(?\d{3}\)?[-\s]?\d{3}[-\s]?\d{4}\b/, 
            type: 'Phone Number',
            replacement: '[Phone Number]',
            explanation: 'Phone number detected'
        },
        { 
            pattern: /\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b/, 
            type: 'Email Address',
            replacement: '[Email]',
            explanation: 'Email address detected'
        },
        { 
            pattern: /\b\d+\s+[A-Za-z\s]+(?:street|st|avenue|ave|road|rd|boulevard|blvd|lane|ln|drive|dr)\b/i, 
            type: 'Full Address',
            replacement: '[Address]',
            explanation: 'Full address detected'
        },
        {
            pattern: /\b[A-Z][a-z]+\s+[A-Z][a-z]+\b/,
            type: 'Full Name',
            replacement: '[Name]',
            explanation: 'Full name detected'
        },
        {
            pattern: /\b\d{1,2}\/\d{1,2}\/\d{4}\b/,
            type: 'Date of Birth',
            replacement: '[Date]',
            explanation: 'Date of birth detected'
        }
    ];

    let hasIssues = false;
    let detectedType = null;
    let suggestion = null;
    let explanation = null;
    let affectedText = userMessage;
    let sensitiveText = null;

    // Find the first matching pattern and create a complete modified message
    for (const { pattern, type, replacement, explanation: patternExplanation } of sensitivePatterns) {
        if (pattern.test(userMessage)) {
            hasIssues = true;
            detectedType = type;
            explanation = patternExplanation;
            
            // Create complete modified message by replacing the sensitive text
            // For better privacy, try to create more natural replacements
            let modifiedMessage = userMessage;
            
            // Handle specific patterns with more natural replacements
            if (type === 'Full Address') {
                // Replace full address with a more natural description
                modifiedMessage = userMessage.replace(pattern, 'a location in the area');
            } else if (type === 'Full Name') {
                // Replace full name with a more natural description
                modifiedMessage = userMessage.replace(pattern, 'someone');
            } else if (type === 'Phone Number') {
                // Replace phone number with a generic placeholder
                modifiedMessage = userMessage.replace(pattern, '[Phone Number]');
            } else if (type === 'Email Address') {
                // Replace email with a generic placeholder
                modifiedMessage = userMessage.replace(pattern, '[Email]');
            } else {
                // Use the default replacement for other patterns
                modifiedMessage = userMessage.replace(pattern, replacement);
            }
            
            suggestion = `Before: "${userMessage}"\nAfter: "${modifiedMessage}"`;
            
            // Extract the matched text
            const match = userMessage.match(pattern);
            if (match) {
                affectedText = match[0];
                sensitiveText = match[0];
            }
            break; // Only handle the first match to avoid multiple replacements
        }
    }

    return {
        privacy_issue: hasIssues,
        type: detectedType,
        suggestion: suggestion,
        explanation: explanation,
        affected_text: affectedText,
        sensitive_text: sensitiveText
    };
}



// Enhanced conversation-wide privacy analysis
async function analyzeConversationPrivacy(conversationHistory) {
    if (!conversationHistory || conversationHistory.length === 0) {
        return { error: 'No conversation history provided' };
    }

    try {
        // Extract all user messages
        const userMessages = conversationHistory
            .filter(msg => msg.role === 'user')
            .map(msg => msg.content);

        if (userMessages.length === 0) {
            return { error: 'No user messages found in conversation' };
        }

        // Analyze each message with conversation context
        const privacyAnalysis = [];
        let totalIssues = 0;

        for (let i = 0; i < userMessages.length; i++) {
            const message = userMessages[i];
            const context = conversationHistory.slice(0, i + 1); // All messages up to current

            try {
                let privacyResult = await detectPrivacyWithAI(message, context);
                if (!privacyResult || privacyResult.error) {
                    privacyResult = detectPrivacyWithPatterns(message, context);
                }

                if (privacyResult.privacy_issue) {
                    totalIssues++;
                }

                privacyAnalysis.push({
                    message_index: i,
                    message: message,
                    privacy_result: privacyResult
                });
            } catch (error) {
                console.error(`Privacy analysis error for message ${i}:`, error);
                privacyAnalysis.push({
                    message_index: i,
                    message: message,
                    privacy_result: { error: error.message }
                });
            }
        }

        // Generate conversation-wide privacy summary
        const summary = {
            total_messages: userMessages.length,
            messages_with_privacy_issues: totalIssues,
            privacy_risk_level: calculateConversationRiskLevel(totalIssues, userMessages.length),
            recommendations: generatePrivacyRecommendations(privacyAnalysis)
        };

        return {
            success: true,
            conversation_analysis: privacyAnalysis,
            summary: summary
        };

    } catch (error) {
        console.error('Conversation privacy analysis error:', error);
        return { error: error.message };
    }
}

// Calculate overall conversation privacy risk level
function calculateConversationRiskLevel(totalIssues, totalMessages) {
    const issuePercentage = (totalIssues / totalMessages) * 100;

    if (issuePercentage > 50) {
        return 'HIGH';
    } else if (issuePercentage > 25) {
        return 'MEDIUM';
    } else if (issuePercentage > 0) {
        return 'LOW';
    } else {
        return 'NONE';
    }
}

// Generate privacy recommendations based on analysis
function generatePrivacyRecommendations(privacyAnalysis) {
    const recommendations = [];
    const issueTypes = new Set();

    privacyAnalysis.forEach(analysis => {
        if (analysis.privacy_result.privacy_issue) {
            if (analysis.privacy_result.type) {
                issueTypes.add(analysis.privacy_result.type);
            }
        }
    });

    if (issueTypes.has('Social Security Number') || issueTypes.has('Credit Card Number')) {
        recommendations.push('CRITICAL: Immediately remove any SSN or credit card information from the conversation');
    }

    if (issueTypes.has('Full Address')) {
        recommendations.push('HIGH: Consider removing or generalizing specific address information');
    }

    if (issueTypes.has('Phone Number') || issueTypes.has('Email Address')) {
        recommendations.push('MEDIUM: Consider removing contact information to prevent unwanted contact');
    }

    if (issueTypes.has('Full Name')) {
        recommendations.push('LOW: Consider using initials or pseudonyms instead of full names');
    }

    if (recommendations.length === 0) {
        recommendations.push('No immediate privacy concerns detected');
    }

    return recommendations;
}

// Analyze Log API with enhanced conversation-wide privacy analysis
app.post('/api/analyze_log', async (req, res) => {
    try {
        const { conversation_log } = req.body;
        
        if (!conversation_log || !Array.isArray(conversation_log)) {
            return res.status(400).json({ error: 'Valid conversation log is required' });
        }

        // Convert conversation log to conversation history format for analysis
        const conversationHistory = conversation_log.map((msg, index) => ({
            role: msg.user ? 'user' : 'assistant',
            content: msg.user || msg.bot || '',
            timestamp: new Date().toISOString(),
            step: index
        }));

        // Use enhanced conversation-wide privacy analysis
        const privacyAnalysis = await analyzeConversationPrivacy(conversationHistory);
        
        if (privacyAnalysis.error) {
            return res.status(500).json({ error: privacyAnalysis.error });
        }

        // Convert back to the expected format for frontend compatibility
        const analyzedLog = conversation_log.map((msg, index) => {
            const privacyResult = privacyAnalysis.conversation_analysis[index];
            return {
                user: msg.user,
                bot: msg.bot,
                privacy: privacyResult && privacyResult.privacy_result.privacy_issue ? privacyResult.privacy_result : null
            };
        });

        res.json({
            success: true,
            analyzed_log: analyzedLog,
            analysis: privacyAnalysis.summary,
            conversation_analysis: privacyAnalysis.conversation_analysis,
            status: 'completed'
        });
    } catch (error) {
        console.error('Log analysis error:', error);
        res.status(500).json({ error: 'Internal server error' });
    }
});

// Apply Privacy Correction API
app.post('/api/apply_privacy_correction', (req, res) => {
    try {
        const { message_index, original_text, corrected_text } = req.body;
        
        if (message_index === undefined || !original_text || !corrected_text) {
            return res.status(400).json({ error: 'All fields are required' });
        }

        // Update the conversation history with the corrected text
        if (conversationHistory[message_index]) {
            conversationHistory[message_index].content = corrected_text;
            conversationHistory[message_index].corrected = true;
            conversationHistory[message_index].original_text = original_text;
        }

        res.json({
            success: true,
            message: 'Correction applied successfully',
            updated_conversation: conversationHistory
        });
    } catch (error) {
        console.error('Apply correction error:', error);
        res.status(500).json({ error: 'Internal server error' });
    }
});

// Upload Questions API
app.post('/api/upload_questions', upload.single('file'), (req, res) => {
    try {
        if (!req.file) {
            return res.status(400).json({ error: 'No file uploaded' });
        }

        const fileContent = fs.readFileSync(req.file.path, 'utf8');
        uploadedQuestions = JSON.parse(fileContent);

        // Clean up uploaded file
        fs.removeSync(req.file.path);

        res.json({
            success: true,
            message: 'Questions uploaded successfully',
            questions_count: uploadedQuestions.length
        });
    } catch (error) {
        console.error('Upload questions error:', error);
        res.status(500).json({ error: 'Failed to process uploaded file' });
    }
});

// Upload Return Log API
app.post('/api/upload_return', upload.single('file'), (req, res) => {
    try {
        if (!req.file) {
            return res.status(400).json({ error: 'No file uploaded' });
        }

        const fileContent = fs.readFileSync(req.file.path, 'utf8');
        uploadedReturnLog = JSON.parse(fileContent);

        // Clean up uploaded file
        fs.removeSync(req.file.path);

        res.json({
            success: true,
            message: 'Return log uploaded successfully',
            log_entries: uploadedReturnLog.length
        });
    } catch (error) {
        console.error('Upload return log error:', error);
        res.status(500).json({ error: 'Failed to process uploaded file' });
    }
});

// Set Mode API
app.post('/api/set_mode', (req, res) => {
    try {
        const { mode } = req.body;
        
        if (!mode) {
            return res.status(400).json({ error: 'Mode is required' });
        }

        currentMode = mode;
        
        res.json({
            success: true,
            message: `Mode set to ${mode}`,
            current_mode: currentMode
        });
    } catch (error) {
        console.error('Set mode error:', error);
        res.status(500).json({ error: 'Internal server error' });
    }
});

// Reset API
app.post('/api/reset', (req, res) => {
    try {
        conversationHistory = [];
        uploadedQuestions = [];
        uploadedReturnLog = [];
        currentMode = 'chat';
        activeChatSession = null; // Reset the chat session to clear context
        
        res.json({
            success: true,
            message: 'Conversation and data reset successfully'
        });
    } catch (error) {
        console.error('Reset error:', error);
        res.status(500).json({ error: 'Internal server error' });
    }
});

// Conversation Privacy Analysis API
app.post('/api/conversation_privacy_analysis', async (req, res) => {
    try {
        const { conversation_history } = req.body;
        
        if (!conversation_history || !Array.isArray(conversation_history)) {
            return res.status(400).json({ error: 'Valid conversation history is required' });
        }

        // Use enhanced conversation-wide privacy analysis
        const privacyAnalysis = await analyzeConversationPrivacy(conversation_history);
        
        if (privacyAnalysis.error) {
            return res.status(500).json({ error: privacyAnalysis.error });
        }

        res.json({
            success: true,
            analysis: privacyAnalysis
        });
    } catch (error) {
        console.error('Conversation privacy analysis error:', error);
        res.status(500).json({ error: 'Internal server error' });
    }
});

// Export API
app.post('/api/export', (req, res) => {
    try {
        const { export_type, data } = req.body;
        
        if (!export_type) {
            return res.status(400).json({ error: 'Export type is required' });
        }

        let exportData = {};
        
        switch (export_type) {
            case 'conversation':
                exportData = {
                    conversation_history: conversationHistory,
                    export_timestamp: new Date().toISOString()
                };
                break;
            case 'analysis':
                exportData = {
                    analysis: data,
                    export_timestamp: new Date().toISOString()
                };
                break;
            case 'privacy_report':
                exportData = {
                    privacy_issues: data,
                    export_timestamp: new Date().toISOString()
                };
                break;
            default:
                return res.status(400).json({ error: 'Invalid export type' });
        }

        res.json({
            success: true,
            data: exportData,
            filename: `${export_type}_${new Date().toISOString().split('T')[0]}.json`
        });
    } catch (error) {
        console.error('Export error:', error);
        res.status(500).json({ error: 'Internal server error' });
    }
});

// Serve the main page
app.get('/', (req, res) => {
    res.sendFile(path.join(__dirname, 'frontend', 'index.html'));
});

// Serve the thanks page
app.get('/thanks', (req, res) => {
    res.sendFile(path.join(__dirname, 'frontend', 'thanks.html'));
});

// Error handling middleware
app.use((error, req, res, next) => {
    console.error('Unhandled error:', error);
    res.status(500).json({ error: 'Internal server error' });
});

// Start server
app.listen(PORT, () => {
    console.log(`Server running on port ${PORT}`);
    console.log(`Frontend available at http://localhost:${PORT}`);
}); 